# Проект для «Викишоп» с BERT
Проект посвященный анализу текстов - ведется предобработка текстов, векторизация - работа с TF-IDF. Решается задача бинарной классификации (токсичность комментария) - ведется выбор оптимальной модели, подбор гипрепараметров, целевая метрика F1. Дополнительно сделана попытка построения модели после подготовки признаков с BERT

## Цель:
Обучить модель классифицировать комментарии на позитивные и негативные. Есть набор данных с разметкой о токсичности правок.
Нужно построить модель со значением метрики качества *F1* не меньше 0.75.


## Вывод:
- видно, что токсичные комментарии короче, как по общей длине так и по числу токенов (в большинстве случаев слов)
- целевой метрики удалось достичь на всем наборе данных с использованием LigtGBMClassifier и LogisticRegeression (с учетом баланса классов и изменением параметра n_gramm_range при созданн счетчика)
- в других моделях целевой метрики не достиг
- для BERT использовал сэмпл с 0.08 выборки - ни одна модель из сэмпла не достигла целевого значения f1
- при примении BERT некоторые модели (при такой же выборке) достигли результатов лучших, чем без него - некоторые нет
- Самый оптимальный про времени и качеству результат дала Логистическая регрессия на все наборе данных

## Стек технологий:
библиотеки pandas, matplotlib, seaborn, sklearn. Модели: LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, LigtGBMClassifier. Кросс-валидация. TF-IDF, BERT.

## Статус проекта:
Завершен
